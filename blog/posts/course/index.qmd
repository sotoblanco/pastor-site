---
title: "An Open Course on LLMs, Led by Practitioners"
description: A free survey course on LLMs, taught by practitioners.
categories: [llms, courses]
css: index.css
author: Hamel Husain
date: 2024-08-02
image: course.png
margin-footer: <br>
---

Today, we are releasing [Mastering LLMs](https://parlance-labs.com/education/), a set of talks and workshops from practitioners on topics like evals, RAG, fine-tuning and more.  It is the first and only course we know of its kind:

-  Taught by 25+ industry veterans who have been working on AI for decades.  We teach best practices that can be transferred to LLMs.
-  Focused on applied topics that are relevant to people building AI products.
-  <ins>**Free and open to everyone**</ins>.

We have meticulously organized and annotated the talks from our popular paid course.[^1] This is a survey course for engineers who have some experience with LLMs and need guidance on how to improve AI products.

[![_Speakers include Jeremy Howard, Sophia Yang, Simon Willison, JJ Allaire, Wing Lian, Mark Saroufim, Jane Xu, Jason Liu, Emmanuel Ameisen, Hailey Schoelkopf, Johno Whitaker, John Berryman, Ben Clavié, Abhishek Thakur, Kyle Corbitt, Ankur Goyal, Freddy Boulton, Jo Bergum, Eugene Yan, Shreya Shankar, Charles Frye, Hamel Husain, Dan Becker and more_](course.png)](https://parlance-labs.com/education/){target="_blank"}


## Getting The Most Value From The Course

### Prerequisites

The course assumes existing familiarity with LLMs.  If you do not have any experience, we recommend watching [A Hacker’s Guide to LLMs](https://www.youtube.com/watch?v=jkrNMKz9pWU).  We also recommend the tutorial [Instruction Tuning llama2](https://www.philschmid.de/instruction-tune-llama-2) to give you background if you are interested in fine-tuning [^2].

### Navigating The Material

The course has over 40 hours of content.  To help you navigate this, we provide:

- **Organization by subject area**: evals, RAG, fine-tuning, building applications and prompt engineering.
- **Chapter summaries:** quickly peruse topics in each talk and skip ahead
- **Notes, slides, and resources**: these are resources used in the talk, as well as resources to learn more.  Many times we have detailed notes as well!

To get started, [navigate to this page](https://parlance-labs.com/education) and peruse topics that you are interested in.  The course isn't meant to be watched linearly, so feel free to jump around and skip bits that aren't interesting or relevant.  However, we did our best to order the talks within each subject that will maximize learning.  We strongly encourage you to use chapter summaries, notes and resources and be selective with your time. Finally, this is a survey course, so it errs on the side of introducing you topics rather than going deeply into code. It's important to leverage the resources and notes to dive deeper into topics that interest you.

### What Students Are Saying

Here are some testimonials from students who have taken the course[^4]:

:::{.testimonial-section}
```{python}
#| output: asis
#| echo: false

from idx import generate_testimonials
testimonials = [
    {
        "image": "sanyam.jpeg",
        "name": "Sanyam Bhutani",
        "title": "Partner Engineer @ Meta",
        "quote": "There was a magical time in 2017 when fastai changed the deep learning world. This course does the same by extending very applied knowledge to LLMs Best in class teachers teach you their knowledge with no fluff"
    },
    {
        "image": "laurian.jpeg",
        "name": "Laurian",
        "title": "Full Stack Computational Linguist",
        "quote": "This course was legendary, still is, and the community on Discord is amazing. I've been through these lessons twice and I have to do it again as there are so many nuances you will get once you actually have those problems on your own deployment.!"
    },
    {
        "image": "andre.png",
        "name": "Andre",
        "title": "CTO",
        "quote": "Amazing! An opinionated view of LLMs, from tools to fine-tuning. Excellent speakers, giving some of the best lectures and advice out there! A lot of real-life experiences and tips you can’t find anywhere on the web packed into this amazing course/workshop/conference! Thanks Dan and Hamel for making this happen!"
    },
    {
        "image": "marcus.png",
        "name": "Marcus",
        "title": "Software Engineer",
        "quote": "The Mastering LLMs conference answered several key questions I had about when to fine-tune base models, building evaluation suits and when to use RAG. The sessions provided a valuable overview of the technical challenges and considerations involved in building and deploying custom LLMs."
    },
    # {
    # "image": "cristi.png",
    # "name": "Cristi",
    # "title": "ML Engineer, Locutus Integrator",
    # "quote": "Awesome way to get from (almost) zero to production with LLMs. Enough theory to understand the need of certain techniques but otherwise everything is focused on 'getting the job done'. I found *very* valuable the expert nuggets about what really matters and what can be skipped for later. And in what corners are the monsters hiding. With this lecture, one can catch up with the concepts and skip a lot of noise and nonsense that is inherent to any growing field."
    # },
    {
    "image": "ali.png",
    "name": "Ali",
    "title": "Principal & Founder, SCTY",
    "quote": "The course that became a conference, filled with a lineup of renowned practitioners whose expertise (and contributions to the field) was only exceeded by their generosity of spirit."
    },
    {
    "image": "lukas.png",
    "name": "Lukas",
    "title": "Software Engineer",
    "quote": "The sheer amount of diverse speakers that cover the same topics from different approaches, both praising and/or degrading certain workflows makes this extremely valuable. Especially when a lot of information online, is produced by those, who are building a commercial product behind, naturally is biased towards a fine tune, a RAG, an open source LLM, an open ai LLM etc. It is rather extra ordinary to have a variety of opinions packed like this. Thank you!"
    },
]

# Generate and print the testimonials
print(generate_testimonials(testimonials))
```
<br>

<center>[Course Website](https://parlance-labs.com/education){target="_blank"}</center>

:::

## Stay Connected

I'm continuously learning about LLMs, and enjoy sharing my findings and thoughts. If you're interested in this journey, consider subscribing to my updates.

What to expect:

- Occasional emails with my latest insights on LLMs
- Early access to new content I'm working on
- No spam, just honest thoughts and discoveries

<script async data-uid="6379a28bdb" src="https://hamel.ck.page/6379a28bdb/index.js"></script>

If you have useful notes or resources for a specific talk, please submit a pull request to [this repo](https://github.com/parlance-labs/website/tree/main/education).


[^1]: https://maven.com/parlance-labs/fine-tuning. I was inspired by [fastai](https://course.fast.ai/) and decided to follow their model of making the course material free and open to everyone. We had more than 2,000 students, with generous gifts from Modal, Replicate, HuggingFace, OpenAI, JarvisLabs, RunPod, Langsmith, OpenPipe, Predibase and more in the form of free compute or credits for students.
[^2]: We find that instruction tuning a model to be a very useful educational experience even if you never intend to fine-tune, because it familiarizes you with topics such as (1) working with open weights models (2) generating synthetic data  (3) managing prompts (4) fine-tuning (5)  and generating predictions.
[^3]: Eventually, tools become so good that they encapsulate good processes.  However, this is often not true for nascent or emerging technologies.  
[^4]: These testimonials are taken from https://maven.com/parlance-labs/fine-tuning.  We have received many more testimonials, but these are a representative sample.
