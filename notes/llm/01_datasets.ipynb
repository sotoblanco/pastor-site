{
 "cells": [
  {
   "cell_type": "raw",
   "id": "61ba75b6-b273-4ace-98bd-a680b52ef5e5",
   "metadata": {},
   "source": [
    "---\n",
    "description: Intro to HuggingFace datasets\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c73f08-e8e6-4c01-9684-16ca8d22ed0a",
   "metadata": {},
   "source": [
    "# Dataset Basics\n",
    "\n",
    "These are some notes on the basics of working with [HF datasets](https://huggingface.co/docs/datasets/index).  These are very important if you want to fine tune LLMs because you will be downloading / uploading datasets from the Hub frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a5c0d-b324-45f5-b77e-5987b9d0f35f",
   "metadata": {},
   "source": [
    "# Highlights\n",
    "\n",
    "- `dataset.map` does some kind of dict merge so `dataset.map(...) that emits a new dict key will add an additional field.\n",
    "- For LLM instruction tuning, you likely want some fields like `features: ['output', 'instruction', 'input']`.  \n",
    "- You can stream data `ds = load_dataset(\"bigcode/the-stack\", streaming=True, split=\"train\")`\n",
    "- using `batched=True` is a good way to speed things up\n",
    "- you can go back and forth from pandas dataframes which is handy for data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fd783-fc9a-4f3d-85ff-95d327c4b853",
   "metadata": {},
   "source": [
    "# Dataset Quickstart\n",
    "\n",
    "Following notes on [this page](https://huggingface.co/docs/datasets/quickstart#nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639391ea-dedf-43d8-af12-7148a6959a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/hamel/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82cf260-3ced-4ccc-a371-c495bd479d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaf8fba-4730-4e57-98bd-5b56f90e2b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99daed99-1dea-4380-9cf4-536dc01bed2f",
   "metadata": {},
   "source": [
    "### Tokenize Data\n",
    "\n",
    "You will want to tokenize examples in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e0093-ee29-41d9-9f78-0845c8064c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9324650-c9c8-4962-b276-dcd15e299270",
   "metadata": {},
   "source": [
    "With just one input, the `token_type_ids` are the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d6e22-7ae6-4adb-a6cd-bd98d9aff401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2054, 2003, 2183, 2006, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('hello what is going on')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454383d-6494-451b-8a5b-6844e6de3337",
   "metadata": {},
   "source": [
    "With two inputs, the `token_type_ids` are indexed accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b07c48-cf90-4e03-81dd-068f867ff26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2054, 2003, 2183, 2006, 1029, 102, 1045, 2572, 2182, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = tokenizer('hello what is going on?',  'I am here.')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a27f9ce-9c82-419b-ad5d-822d53409f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] hello what is going on? [SEP]\n",
      "i am here. [SEP]\n"
     ]
    }
   ],
   "source": [
    "groups = [[], []]\n",
    "for i,tt in zip(out['input_ids'], out['token_type_ids']):\n",
    "    groups[tt].append(i)\n",
    "    \n",
    "for g in groups:\n",
    "    print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(g)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079e15e2-bc3e-46f5-9e1c-0c89a6cc9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(examples):\n",
    "    return tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], truncation=True, padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1132bac9-1a36-4c3d-a862-51ba0af481df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca4cd70057746d896c7f31a0de55341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = dataset.map(encode, batched=True)\n",
    "tds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34422639-ffa5-4b3e-9a40-8f5c99206555",
   "metadata": {},
   "source": [
    "### Add additional field / change col name\n",
    "\n",
    "The quickstart says that the model requires the field name `labels`.  How would we know?  We can look at the `forward` method of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa6db9-2155-48cc-89db-387acbfe9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mposition_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhead_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minputs_embeds\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequenceClassifierOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The [`BertForSequenceClassification`] forward method, overrides the `__call__` special method.\n",
       "\n",
       "<Tip>\n",
       "\n",
       "Although the recipe for forward pass needs to be defined within this function, one should call the [`Module`]\n",
       "instance afterwards instead of this since the former takes care of running the pre and post processing steps while\n",
       "the latter silently ignores them.\n",
       "\n",
       "</Tip>\n",
       "\n",
       "Args:\n",
       "    input_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`):\n",
       "        Indices of input sequence tokens in the vocabulary.\n",
       "\n",
       "        Indices can be obtained using [`BertTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
       "        [`PreTrainedTokenizer.__call__`] for details.\n",
       "\n",
       "        [What are input IDs?](../glossary#input-ids)\n",
       "    attention_mask (`torch.FloatTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
       "        Mask to avoid performing attention on padding token indices. Mask values selected in `[0, 1]`:\n",
       "\n",
       "        - 1 for tokens that are **not masked**,\n",
       "        - 0 for tokens that are **masked**.\n",
       "\n",
       "        [What are attention masks?](../glossary#attention-mask)\n",
       "    token_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
       "        Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
       "        1]`:\n",
       "\n",
       "        - 0 corresponds to a *sentence A* token,\n",
       "        - 1 corresponds to a *sentence B* token.\n",
       "\n",
       "        [What are token type IDs?](../glossary#token-type-ids)\n",
       "    position_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
       "        Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
       "        config.max_position_embeddings - 1]`.\n",
       "\n",
       "        [What are position IDs?](../glossary#position-ids)\n",
       "    head_mask (`torch.FloatTensor` of shape `(num_heads,)` or `(num_layers, num_heads)`, *optional*):\n",
       "        Mask to nullify selected heads of the self-attention modules. Mask values selected in `[0, 1]`:\n",
       "\n",
       "        - 1 indicates the head is **not masked**,\n",
       "        - 0 indicates the head is **masked**.\n",
       "\n",
       "    inputs_embeds (`torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size)`, *optional*):\n",
       "        Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
       "        is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
       "        model's internal embedding lookup matrix.\n",
       "    output_attentions (`bool`, *optional*):\n",
       "        Whether or not to return the attentions tensors of all attention layers. See `attentions` under returned\n",
       "        tensors for more detail.\n",
       "    output_hidden_states (`bool`, *optional*):\n",
       "        Whether or not to return the hidden states of all layers. See `hidden_states` under returned tensors for\n",
       "        more detail.\n",
       "    return_dict (`bool`, *optional*):\n",
       "        Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n",
       "\n",
       "    labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
       "        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
       "        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
       "        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
       "    \n",
       "Returns:\n",
       "    [`transformers.modeling_outputs.SequenceClassifierOutput`] or `tuple(torch.FloatTensor)`: A [`transformers.modeling_outputs.SequenceClassifierOutput`] or a tuple of\n",
       "    `torch.FloatTensor` (if `return_dict=False` is passed or when `config.return_dict=False`) comprising various\n",
       "    elements depending on the configuration ([`BertConfig`]) and inputs.\n",
       "\n",
       "    - **loss** (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) -- Classification (or regression if config.num_labels==1) loss.\n",
       "    - **logits** (`torch.FloatTensor` of shape `(batch_size, config.num_labels)`) -- Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
       "    - **hidden_states** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`) -- Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "      one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "      Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
       "    - **attentions** (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`) -- Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "      sequence_length)`.\n",
       "\n",
       "      Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
       "      heads.\n",
       "\n",
       "Example of single-label classification:\n",
       "\n",
       "```python\n",
       ">>> import torch\n",
       ">>> from transformers import BertTokenizer, BertForSequenceClassification\n",
       "\n",
       ">>> tokenizer = BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
       ">>> model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
       "\n",
       ">>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
       "\n",
       ">>> with torch.no_grad():\n",
       "...     logits = model(**inputs).logits\n",
       "\n",
       ">>> predicted_class_id = logits.argmax().item()\n",
       ">>> model.config.id2label[predicted_class_id]\n",
       "'LABEL_1'\n",
       "```\n",
       "\n",
       "```python\n",
       ">>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
       ">>> num_labels = len(model.config.id2label)\n",
       ">>> model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\", num_labels=num_labels)\n",
       "\n",
       ">>> labels = torch.tensor([1])\n",
       ">>> loss = model(**inputs, labels=labels).loss\n",
       ">>> round(loss.item(), 2)\n",
       "0.01\n",
       "```\n",
       "\n",
       "Example of multi-label classification:\n",
       "\n",
       "```python\n",
       ">>> import torch\n",
       ">>> from transformers import BertTokenizer, BertForSequenceClassification\n",
       "\n",
       ">>> tokenizer = BertTokenizer.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\")\n",
       ">>> model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-yelp-polarity\", problem_type=\"multi_label_classification\")\n",
       "\n",
       ">>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
       "\n",
       ">>> with torch.no_grad():\n",
       "...     logits = model(**inputs).logits\n",
       "\n",
       ">>> predicted_class_id = logits.argmax().item()\n",
       ">>> model.config.id2label[predicted_class_id]\n",
       "'LABEL_1'\n",
       "```\n",
       "\n",
       "```python\n",
       ">>> # To train a model on `num_labels` classes, you can pass `num_labels=num_labels` to `.from_pretrained(...)`\n",
       ">>> num_labels = len(model.config.id2label)\n",
       ">>> model = BertForSequenceClassification.from_pretrained(\n",
       "...     \"textattack/bert-base-uncased-yelp-polarity\", num_labels=num_labels, problem_type=\"multi_label_classification\"\n",
       "... )\n",
       "\n",
       ">>> labels = torch.nn.functional.one_hot(torch.tensor([predicted_class_id]), num_classes=num_labels).to(\n",
       "...     torch.float\n",
       "... )\n",
       ">>> loss = model(**inputs, labels=labels).loss\n",
       ">>> loss.backward()  # doctest: +IGNORE_RESULT\n",
       "```\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?model.forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0d971-e3b0-4703-8cb3-5ad13c176ffb",
   "metadata": {},
   "source": [
    "Change `label` to `labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901a57b-4790-4798-8a3d-0ef6548ea1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00101b7a92364254a9bd90dc83d86075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds = tds.map(lambda examples: {\"labels\": examples[\"label\"]}, batched=True)\n",
    "tds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488abba-3acc-4be0-8462-78a3ebcaa66d",
   "metadata": {},
   "source": [
    "### Turn Dataset into a pytorch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bccca8a-9822-4a0f-ae93-a29c51783e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tds.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "dataloader = torch.utils.data.DataLoader(tds, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb24feb-456e-40d4-8558-00941b798e61",
   "metadata": {},
   "source": [
    "## Wikipedia Dataset\n",
    "\n",
    "There seems to be many subsets. [This is the page](https://huggingface.co/datasets/wikitext/viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61706e5c-f731-4977-9737-0b4d0c3cf0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"wikitext\", \"wikitext-2-v1\", streaming=True, split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a1799-5725-4898-85f1-e6f5e98ec6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = ds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779e92b-f3bc-410b-9af1-38f7db18a08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified\\n Good and Featured articles on Wikipedia. The dataset is available under the Creative Commons Attribution-ShareAlike\\n License.\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9952c8-71d0-4937-92d7-dbf1885ca28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ''},\n",
       " {'text': ' = Homarus gammarus = \\n'},\n",
       " {'text': ''},\n",
       " {'text': ' Homarus gammarus , known as the European lobster or common lobster , is a species of <unk> lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into <unk> larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . \\n'},\n",
       " {'text': ''}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d338700-cc97-4d61-8f7d-52853929c086",
   "metadata": {},
   "source": [
    "# Loading Custom Dataset\n",
    "\n",
    "You can load a dataset from `csv, tsv, text, json, jsonl, dataframes`\n",
    "You can also point to a url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb1070-2b55-493e-ace5-5400b4cc96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-6e1837ea838b9492\n",
      "Found cached dataset csv (/Users/hamel/.cache/huggingface/datasets/csv/default-6e1837ea838b9492/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044be4856c874efca290f4a999dceee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"csv\", data_files=\"https://github.com/datablist/sample-csv-files/raw/main/files/customers/customers-500000.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457446e-51e4-4a88-b230-b130d6cc6018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website'],\n",
       "        num_rows: 500000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb375f-4667-49a4-a4dc-535f3bae8270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': 1,\n",
       " 'Customer Id': 'e685B8690f9fbce',\n",
       " 'First Name': 'Erik',\n",
       " 'Last Name': 'Little',\n",
       " 'Company': 'Blankenship PLC',\n",
       " 'City': 'Caitlynmouth',\n",
       " 'Country': 'Sao Tome and Principe',\n",
       " 'Phone 1': '457-542-6899',\n",
       " 'Phone 2': '055.415.2664x5425',\n",
       " 'Email': 'shanehester@campbell.org',\n",
       " 'Subscription Date': '2021-12-23',\n",
       " 'Website': 'https://wagner.com/'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682bec67-cff4-4bb0-8274-de1d720836d9",
   "metadata": {},
   "source": [
    "## Transformations\n",
    "\n",
    "### `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4839490c-1f8a-4fac-96b6-94a08673e5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1090cd933294dcfa41ca71687ab2be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fullnm(d): return {'Full Name': d['First Name'] + ' ' + d['Last Name']}\n",
    "ds = ds.map(fullnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8859b83-d173-4a60-8ea5-672e83bacf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': 1,\n",
       " 'Customer Id': 'e685B8690f9fbce',\n",
       " 'First Name': 'Erik',\n",
       " 'Last Name': 'Little',\n",
       " 'Company': 'Blankenship PLC',\n",
       " 'City': 'Caitlynmouth',\n",
       " 'Country': 'Sao Tome and Principe',\n",
       " 'Phone 1': '457-542-6899',\n",
       " 'Phone 2': '055.415.2664x5425',\n",
       " 'Email': 'shanehester@campbell.org',\n",
       " 'Subscription Date': '2021-12-23',\n",
       " 'Website': 'https://wagner.com/',\n",
       " 'Full Name': 'Erik Little'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5d1cb-c8d3-4d76-8d99-ac6379a2dcfc",
   "metadata": {},
   "source": [
    "#### `batched=True` for `map`\n",
    "\n",
    "You operate over a list instead of single items, this can usually speed things up a bit.  The below example is significantly faster than the default.\n",
    "\n",
    "per [the docs](https://huggingface.co/learn/nlp-course/chapter5/3?fw=pt#the-map-methods-superpowers):\n",
    "\n",
    "> list comprehensions are usually faster than executing the same code in a for loop, and we also gain some performance by accessing lots of elements at the same time instead of one by one.\n",
    "\n",
    "> Using Dataset.map() with batched=True will be essential to unlock the speed of the “fast” tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109c464-fa9f-4ee3-8167-4580394751ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7979bedfda0454eb6d50f81055e034b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Phone 1', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 500000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fullnm_batched(d): return {'Full Name': [f + ' ' + l for f,l in zip(d['First Name'], d['Last Name'])]}\n",
    "ds.map(fullnm_batched, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bcfb6-8e61-46ad-abf7-dd361a1ae3df",
   "metadata": {},
   "source": [
    "#### `batched=True` speed test\n",
    "\n",
    "HF tokenizers can work with or without `batch=True`, let's see the difference, first let's make a text field, let's use a dataset with a larger text field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb54718a-fcd2-4e9a-9e50-4780c84fbfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import set_caching_enabled\n",
    "set_caching_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73bc1a-0e01-4739-b9ed-53d15366e972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3340c354bf896b6f\n",
      "Found cached dataset csv (/Users/hamel/.cache/huggingface/datasets/csv/default-3340c354bf896b6f/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c226ed63094d66afa480575b9ea728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tds = load_dataset(\"csv\",\n",
    "                   data_files='https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip',\n",
    "                   delimiter=\"\\t\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd33897-f91a-4d4c-a399-526925605898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"I&#039;ve tried a few antidepressants over the years (citalopram, fluoxetine, amitriptyline), but none of those helped with my depression, insomnia &amp; anxiety. My doctor suggested and changed me onto 45mg mirtazapine and this medicine has saved my life. Thankfully I have had no side effects especially the most common - weight gain, I&#039;ve actually lost alot of weight. I still have suicidal thoughts but mirtazapine has saved me.\"'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds['train']['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bebf5ae-3831-41ca-86ce-37a4b83c8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples): return tokenizer(examples[\"review\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d4cd63-4c8d-483f-a4c4-a6a4e7a18656",
   "metadata": {},
   "source": [
    "##### Without `batched`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b55b9b-ec49-418d-ad12-c64d11e13952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa6c2aa905745de97e06d379f96970b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215063 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 21s, sys: 1.71 s, total: 1min 23s\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 215063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tds.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1cca0-f12c-4058-a586-a64305d8fa72",
   "metadata": {},
   "source": [
    "##### With `batched`\n",
    "\n",
    "19 Seconds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987d8e5-f675-4624-a7ec-5b7bc670e850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2884a4087bd54bbbbb2f9eaf01b55dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/216 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 5s, sys: 1.18 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 215063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f1c8e-4186-4a83-8769-fbcacce42828",
   "metadata": {},
   "source": [
    "#### Multicore\n",
    "\n",
    "15.7s!\n",
    "\n",
    ">  for values of num_proc other than 8, our tests showed that it was faster to use batched=True without that option. In general, we don’t recommend using Python multiprocessing for fast tokenizers with batched=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf810b-92a0-479b-9182-223cdedf6295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a242bf37094a42a7e6cb3fef30ce3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d94460e84604ad7b01b3b1f73f222da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bd6b1bf84c4f16ad416786b8934751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7cacd514f44f96aed17d324b7c34ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272b750d82d7405c8c57a2b914139690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92259bb82774692a4616aa383000958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99763d230ad54cd19a00e5adec6a843a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e60851b8c147dfa1ad70819abe0b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/27 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 911 ms, sys: 533 ms, total: 1.44 s\n",
      "Wall time: 18.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 215063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time tds.map(tokenize_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45145e4-4f50-4c71-89d6-6c836ae2562d",
   "metadata": {},
   "source": [
    "### `select`\n",
    "\n",
    "Good to see a preview of different rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45709d2-a7f7-4cac-9845-d2dea7bc45a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': [209712, 246986],\n",
       " 'Customer Id': ['fad0d3B75B73cd7', 'D75eCaeAc8C6BD6'],\n",
       " 'First Name': ['Jo', 'Judith'],\n",
       " 'Last Name': ['Pittman', 'Thomas'],\n",
       " 'Company': ['Pineda-Hobbs', 'Mcguire, Alvarado and Kennedy'],\n",
       " 'City': ['Traciestad', 'Palmerfort'],\n",
       " 'Country': ['Finland', 'Tonga'],\n",
       " 'Phone 1': ['001-086-011-7063', '+1-495-667-1061x21703'],\n",
       " 'Phone 2': ['853-679-2287x631', '589.777.0504'],\n",
       " 'Email': ['gsantos@stuart.biz', 'vchung@bowman.com'],\n",
       " 'Subscription Date': ['2020-08-04', '2021-08-14'],\n",
       " 'Website': ['https://www.bautista.com/', 'https://wilkerson.org/'],\n",
       " 'Full Name': ['Jo Pittman', 'Judith Thomas']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ds['train'].shuffle(seed=42).select(range(10))\n",
    "sample[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0fc1db-75a8-46db-b381-0af39ac27c7b",
   "metadata": {},
   "source": [
    "### `unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516697a-4466-4a3d-919f-4653dd05592b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, {'train': 500000})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds['train'].unique('Index')), ds.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1dcf1-add5-4f2c-8e65-361526805700",
   "metadata": {},
   "source": [
    "### `rename_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f406ea-8049-42c1-9d36-ba8db82070fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rename_column('Phone 1', new_column_name='Primary Phone Number')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252093db-477c-4892-a4ed-c041fc42554d",
   "metadata": {},
   "source": [
    "### `filter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc5e7f0-4851-4df8-a412-fd0c74857176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47777ca2137d4ea390fb44e91f59b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def erik(d): return d['First Name'].lower() == 'erik'\n",
    "\n",
    "e_ds = ds.filter(erik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d64085f-6144-4b3e-b7dd-3188e00f1be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Erik', 'Erik', 'Erik', 'Erik', 'Erik']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_ds['train'].select(range(5))['First Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df766b33-334e-458a-bec8-1e20edc9defb",
   "metadata": {},
   "source": [
    "### `sort`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809256fe-15f3-428b-8533-2a683e85d067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': [491821, 170619, 212021],\n",
       " 'Customer Id': ['84C747dDFac8Dc7', '5886eaffEF8dc6D', 'B8a6cFab936Fb2A'],\n",
       " 'First Name': ['Aaron', 'Aaron', 'Aaron'],\n",
       " 'Last Name': ['Hull', 'Cain', 'Mays'],\n",
       " 'Company': ['Morrow Inc', 'Mccormick-Hardy', 'Hopkins-Larson'],\n",
       " 'City': ['West Charles', 'West Connie', 'Mccallchester'],\n",
       " 'Country': ['Netherlands', 'Vanuatu', 'Ecuador'],\n",
       " 'Primary Phone Number': ['670-796-3507',\n",
       "  '323-296-0014',\n",
       "  '(594)960-9651x17240'],\n",
       " 'Phone 2': ['001-917-832-0423x324',\n",
       "  '+1-551-114-3103x05351',\n",
       "  '996.174.5737x6442'],\n",
       " 'Email': ['ivan16@bender.org',\n",
       "  'shelley82@bender.org',\n",
       "  'qrhodes@stokes-larson.info'],\n",
       " 'Subscription Date': ['2020-05-28', '2021-04-11', '2022-03-19'],\n",
       " 'Website': ['http://carney-lawson.info/',\n",
       "  'http://www.wiggins.biz/',\n",
       "  'http://pugh.com/'],\n",
       " 'Full Name': ['Aaron Hull', 'Aaron Cain', 'Aaron Mays']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'].sort('First Name').select(range(10))[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6ee20e-543f-4c65-8320-5c670201a0c6",
   "metadata": {},
   "source": [
    "## Dataframes from datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5146bc8-a7ee-4180-9a42-ae8afc4429ac",
   "metadata": {},
   "source": [
    "`set_format` seems to work in place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d347b4-f4ab-4fa7-ba2f-18b4cb5fca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_format('pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e6b5a4-d70a-4650-b9cf-b60f4d3e1aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Customer Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Company</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Primary Phone Number</th>\n",
       "      <th>Phone 2</th>\n",
       "      <th>Email</th>\n",
       "      <th>Subscription Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>Full Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>e685B8690f9fbce</td>\n",
       "      <td>Erik</td>\n",
       "      <td>Little</td>\n",
       "      <td>Blankenship PLC</td>\n",
       "      <td>Caitlynmouth</td>\n",
       "      <td>Sao Tome and Principe</td>\n",
       "      <td>457-542-6899</td>\n",
       "      <td>055.415.2664x5425</td>\n",
       "      <td>shanehester@campbell.org</td>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>https://wagner.com/</td>\n",
       "      <td>Erik Little</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6EDdBA3a2DFA7De</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>Shaw</td>\n",
       "      <td>Jensen and Sons</td>\n",
       "      <td>Janetfort</td>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>9610730173</td>\n",
       "      <td>531-482-3000x7085</td>\n",
       "      <td>kleinluis@vang.com</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>https://www.paul.org/</td>\n",
       "      <td>Yvonne Shaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>b9Da13bedEc47de</td>\n",
       "      <td>Jeffery</td>\n",
       "      <td>Ibarra</td>\n",
       "      <td>Rose, Deleon and Sanders</td>\n",
       "      <td>Darlenebury</td>\n",
       "      <td>Albania</td>\n",
       "      <td>(840)539-1797x479</td>\n",
       "      <td>209-519-5817</td>\n",
       "      <td>deckerjamie@bartlett.biz</td>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>https://www.morgan-phelps.com/</td>\n",
       "      <td>Jeffery Ibarra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>710D4dA2FAa96B5</td>\n",
       "      <td>James</td>\n",
       "      <td>Walters</td>\n",
       "      <td>Kline and Sons</td>\n",
       "      <td>Donhaven</td>\n",
       "      <td>Bahrain</td>\n",
       "      <td>+1-985-596-1072x3040</td>\n",
       "      <td>(528)734-8924x054</td>\n",
       "      <td>dochoa@carey-morse.com</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>https://brennan.com/</td>\n",
       "      <td>James Walters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3c44ed62d7BfEBC</td>\n",
       "      <td>Leslie</td>\n",
       "      <td>Snyder</td>\n",
       "      <td>Price, Mason and Doyle</td>\n",
       "      <td>Mossfort</td>\n",
       "      <td>Central African Republic</td>\n",
       "      <td>812-016-9904x8231</td>\n",
       "      <td>254.631.9380</td>\n",
       "      <td>darrylbarber@warren.org</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>http://www.trujillo-sullivan.info/</td>\n",
       "      <td>Leslie Snyder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index      Customer Id First Name Last Name                   Company  \\\n",
       "0      1  e685B8690f9fbce       Erik    Little           Blankenship PLC   \n",
       "1      2  6EDdBA3a2DFA7De     Yvonne      Shaw           Jensen and Sons   \n",
       "2      3  b9Da13bedEc47de    Jeffery    Ibarra  Rose, Deleon and Sanders   \n",
       "3      4  710D4dA2FAa96B5      James   Walters            Kline and Sons   \n",
       "4      5  3c44ed62d7BfEBC     Leslie    Snyder    Price, Mason and Doyle   \n",
       "\n",
       "           City                   Country  Primary Phone Number  \\\n",
       "0  Caitlynmouth     Sao Tome and Principe          457-542-6899   \n",
       "1     Janetfort     Palestinian Territory            9610730173   \n",
       "2   Darlenebury                   Albania     (840)539-1797x479   \n",
       "3      Donhaven                   Bahrain  +1-985-596-1072x3040   \n",
       "4      Mossfort  Central African Republic     812-016-9904x8231   \n",
       "\n",
       "             Phone 2                     Email Subscription Date  \\\n",
       "0  055.415.2664x5425  shanehester@campbell.org        2021-12-23   \n",
       "1  531-482-3000x7085        kleinluis@vang.com        2021-01-01   \n",
       "2       209-519-5817  deckerjamie@bartlett.biz        2020-03-30   \n",
       "3  (528)734-8924x054    dochoa@carey-morse.com        2022-01-18   \n",
       "4       254.631.9380   darrylbarber@warren.org        2020-01-25   \n",
       "\n",
       "                              Website       Full Name  \n",
       "0                 https://wagner.com/     Erik Little  \n",
       "1               https://www.paul.org/     Yvonne Shaw  \n",
       "2      https://www.morgan-phelps.com/  Jeffery Ibarra  \n",
       "3                https://brennan.com/   James Walters  \n",
       "4  http://www.trujillo-sullivan.info/   Leslie Snyder  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7a17b-6b16-4422-bd4c-5946c656b8d9",
   "metadata": {},
   "source": [
    "You can get a proper pandas dataframe like this:\n",
    "\n",
    "> 🚨 Under the hood, Dataset.set_format() changes the return format for the dataset’s __getitem__() dunder method. This means that when we want to create a new object like train_df from a Dataset in the \"pandas\" format, we need to slice the whole dataset to obtain a pandas.DataFrame. You can verify for yourself that the type of drug_dataset[\"train\"] is Dataset, irrespective of the output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99982ff4-58a6-4a6c-be42-b597f79ccea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'][:]\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afd753-8fef-41d4-9f03-8cbef7c37c0b",
   "metadata": {},
   "source": [
    "## Datasets from DataFrames\n",
    "\n",
    "This is going the other direction df -> ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbcf9d-e60c-4493-a42d-f8eafd7fdd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "    num_rows: 500000\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds = dataset.from_pandas(df)\n",
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ab01d-b66b-4d2d-838c-5066b65cc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Index': [1, 2],\n",
       " 'Customer Id': ['e685B8690f9fbce', '6EDdBA3a2DFA7De'],\n",
       " 'First Name': ['Erik', 'Yvonne'],\n",
       " 'Last Name': ['Little', 'Shaw'],\n",
       " 'Company': ['Blankenship PLC', 'Jensen and Sons'],\n",
       " 'City': ['Caitlynmouth', 'Janetfort'],\n",
       " 'Country': ['Sao Tome and Principe', 'Palestinian Territory'],\n",
       " 'Primary Phone Number': ['457-542-6899', '9610730173'],\n",
       " 'Phone 2': ['055.415.2664x5425', '531-482-3000x7085'],\n",
       " 'Email': ['shanehester@campbell.org', 'kleinluis@vang.com'],\n",
       " 'Subscription Date': ['2021-12-23', '2021-01-01'],\n",
       " 'Website': ['https://wagner.com/', 'https://www.paul.org/'],\n",
       " 'Full Name': ['Erik Little', 'Yvonne Shaw']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4270563-cd71-4191-8b1a-a558041a8727",
   "metadata": {},
   "source": [
    "### Reset the format\n",
    "Note you can reset the format at anytime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172efcab-0dce-42b4-bf13-c74b917fbb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.set_format('pandas')\n",
    "type(new_ds[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6fd06-9286-447e-b580-eeb03aaa425d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds.reset_format()\n",
    "type(new_ds[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302d554-7573-4425-87b2-9c103e635c21",
   "metadata": {},
   "source": [
    "## Creating data partitions\n",
    "\n",
    "train/test etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb95514-229b-4bfd-91a7-fe89a190e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ds = new_ds.train_test_split(train_size=0.8, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fc6a67-5f6e-44d3-ae82-469a5ad4fa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 400000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c67774-c7ce-433e-bf51-7aaf88dec9eb",
   "metadata": {},
   "source": [
    "You can create new partitions without `train_test_split` explicitly by creating a new group like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458d0b6f-11d0-4eae-a678-c2e888f5db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ds2 = split_ds['train'].train_test_split(train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85063e01-2da1-46f2-92b2-99d90ec07f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ds['train'] = split_ds2['train']\n",
    "split_ds['validation'] = split_ds2['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15870a41-d049-4d6f-807e-f41d8be9fad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 320000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 80000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046f0e99-2e85-4edc-ab92-3c253c6e957c",
   "metadata": {},
   "source": [
    "# Saving & Loading Datasets\n",
    "\n",
    "Let's save our ds dataset to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d85f7-6a73-4e4e-a670-c6a382e2beac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "    num_rows: 500000\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6b92e-c216-4341-a2a2-d8cf9799a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds.save_to_disk('tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14eb3a1-9bb3-43b2-91f2-017c6c5a1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mtabular_data\u001b[00m\n",
      "├── dataset.arrow\n",
      "├── dataset_dict.json\n",
      "├── dataset_info.json\n",
      "├── state.json\n",
      "└── \u001b[01;34mtrain\u001b[00m\n",
      "    ├── dataset.arrow\n",
      "    ├── dataset_info.json\n",
      "    └── state.json\n",
      "\n",
      "1 directory, 7 files\n"
     ]
    }
   ],
   "source": [
    "!tree tabular_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61faf88-4162-4f7c-b2d4-d73c6a766cb5",
   "metadata": {},
   "source": [
    "Load the data now from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4635ac97-7a9a-4b9a-9600-c77b1f7ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_disk_ds = dataset.load_from_disk('tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927ca40-bb18-42eb-b2d9-dc6a0efda752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "    num_rows: 500000\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_disk_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e9e0a8-deee-4f6f-937a-c245d1c04cca",
   "metadata": {},
   "source": [
    "# Streaming a `dataset`\n",
    "\n",
    "When you set `streaming=True` you are returned a `IterableDataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba73744-f4ec-4d04-afda-62b7d2e48b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.iterable_dataset.IterableDataset"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds = load_dataset(\"wikitext\", \"wikitext-2-v1\", \n",
    "                  streaming=True, split=\"validation\")\n",
    "type(sds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a17bb1-faa4-4ac1-b2f4-c4e181ef51fd",
   "metadata": {},
   "source": [
    "## `take` and `skip`\n",
    "\n",
    "These are special methods for `IterableDataset`, these will not work for a regular `dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc5251-42bc-4cab-adca-d2a25471e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': ''},\n",
       " {'text': ' = Homarus gammarus = \\n'},\n",
       " {'text': ''},\n",
       " {'text': ' Homarus gammarus , known as the European lobster or common lobster , is a species of <unk> lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into <unk> larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . \\n'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sds.take(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47924af-69b8-4200-95ef-23ae4a363233",
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = list(sds.skip(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b2280e-90ab-46ed-8f5d-ccc458903a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 3760)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(foo), len(list(sds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640b0320-b19c-493f-a9ae-f8aaa37e7021",
   "metadata": {},
   "source": [
    "you can use `itertools.islice` to get multiple items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679fe32-1104-4959-905c-f1fa378477c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "len(list(islice(sds, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280aedd8-b00b-408c-b0e9-b50d397efe59",
   "metadata": {},
   "source": [
    "The old way looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47207725-eaeb-4946-b0c5-f28e7e13bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/hamel/.cache/huggingface/datasets/wikitext/wikitext-2-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nds = load_dataset(\"wikitext\", \"wikitext-2-v1\", \n",
    "                   split=\"validation\")\n",
    "type(nds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48920999-7956-447e-a013-0c96fde15c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Index', 'Customer Id', 'First Name', 'Last Name', 'Company', 'City', 'Country', 'Primary Phone Number', 'Phone 2', 'Email', 'Subscription Date', 'Website', 'Full Name'],\n",
       "        num_rows: 500000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2081bf-77b4-454a-a542-884636842aa3",
   "metadata": {},
   "source": [
    "# Uploading Datset to the Hub\n",
    "\n",
    "See [the docs](https://huggingface.co/learn/nlp-course/chapter5/5?fw=pt#uploading-the-dataset-to-the-hugging-face-hub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00766ddc-1185-4662-a689-12d213179661",
   "metadata": {},
   "source": [
    "## Login & upload with notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283e7f6-8ccd-4973-9b2a-0de20fae7908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e24b41b51dc457f8d29db7e3671e1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc89d5-a4de-4da5-b217-9da27b30f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_disk_ds = dataset.load_from_disk('tabular_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5807b1b-3299-4916-841f-cd41b8c544b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4bf8ef5b4444ecb3f86b2181bb8ce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397d7acd89314ec2ab9a51f2d69aa7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating downloaded metadata with the new split.\n"
     ]
    }
   ],
   "source": [
    "remote_name = 'hamel/tabular-data-test'\n",
    "from_disk_ds.push_to_hub(remote_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246b7a2-d848-402b-94c2-9ed2a1bf03a0",
   "metadata": {},
   "source": [
    "## Using the cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fbcd2-f6e7-4dd2-b663-17670bba9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: huggingface-cli <command> [<args>]\n",
      "\n",
      "positional arguments:\n",
      "  {login,whoami,logout,repo,lfs-enable-largefiles,lfs-multipart-upload}\n",
      "                        huggingface-cli command helpers\n",
      "    login               Log in using a token from\n",
      "                        huggingface.co/settings/tokens\n",
      "    whoami              Find out which huggingface.co account you are logged\n",
      "                        in as.\n",
      "    logout              Log out\n",
      "    repo                {create, ls-files} Commands to interact with your\n",
      "                        huggingface.co repos.\n",
      "    lfs-enable-largefiles\n",
      "                        Configure your repository to enable upload of files >\n",
      "                        5GB.\n",
      "    lfs-multipart-upload\n",
      "                        Command will get called by git-lfs, do not call it\n",
      "                        directly.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1849cf27-f3d2-4c30-a48e-82d95c61e71f",
   "metadata": {},
   "source": [
    "You can use `huggingface-cli login` to login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6457e7-47f2-4f70-a6d4-21f55d5f4e8e",
   "metadata": {},
   "source": [
    "HF datasets are just git repos!  You can clone a repo like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cebd9-941f-4819-acae-f48726a80f56",
   "metadata": {},
   "source": [
    "### Datasets are Git repos\n",
    "\n",
    "HF datasets are just git repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993a2a8-d4cd-464b-b441-6a49695eea77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tabular-data-test'...\n",
      "remote: Enumerating objects: 13, done.\u001b[K\n",
      "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 13 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (13/13), 1.93 KiB | 164.00 KiB/s, done.\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m               dataset_infos.json\n"
     ]
    }
   ],
   "source": [
    "_dir = remote_name.split('/')[-1]\n",
    "\n",
    "!rm -rf {_dir}\n",
    "!git clone 'https://huggingface.co/datasets/'{remote_name}\n",
    "!ls {_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477e1d9-358a-4471-b130-a4ec1e5deb73",
   "metadata": {},
   "source": [
    "The parquet file is here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e6394-9025-4826-81e4-f13fdd0eea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-00000-of-00001-646295d7cc3e7eab.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls {_dir}'/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dab7dc-2373-4cdf-952e-6be4b365fa97",
   "metadata": {},
   "source": [
    "## Dataset Cards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d524301-cc3b-4980-8ae0-c0205779b0fd",
   "metadata": {},
   "source": [
    "1. You specify the dataset card by filling out the `README.md` file.  In the Hub there is a README creation tool that has a template you can fill out.\n",
    "2. There are tags for the dataset that you can set in the front matter of the README.  [This is an example](https://raw.githubusercontent.com/huggingface/datasets/main/templates/README_guide.md).  [This application](https://huggingface.co/spaces/huggingface/datasets-tagging) can help you generate the tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a45a7-7271-49dc-a4c2-8ab27656c5c5",
   "metadata": {},
   "source": [
    "# FAISS Semantic Search\n",
    "\n",
    "See [this lesson](https://huggingface.co/learn/nlp-course/chapter5/6?fw=tf). HF datasets have really nice built-in tools to do semantic search.  This is really useful and fun."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
