---
title: TF Serving
description: TensorFlow Serving
metadata-files: ["../../_listing_meta.yml"]
---

## Why use TFServing?

- Offers a gRPC endpoint that can offer better compression of payloads relative to REST.  This helps with larger payloads like images, where tensors are larger. 
- GPU [batching support](https://www.tensorflow.org/tfx/serving/serving_config#batching_configuration): which can batch requests together and send them to the GPU in a single call.  This can help with latency and throughput.  This isn't free though and requires tuning to get right.
-  [Model versioning](https://www.tensorflow.org/tfx/serving/serving_config#serving_a_specific_version_of_a_model):  Allows you to deploy multiple versions of a model and route traffic to them.  This is useful for A/B testing and canary deployments.  In addition to model version numbers, you can [assign these versions to labels](https://www.tensorflow.org/tfx/serving/serving_config#batching_configuration), like "canary" and "stable" which can be accessible at an endpoint like `/v1/models/<model name>/labels/<version label>`
- You can change what TF-Serving returns beyond just the output of the last layer of the model; for example, you can return the output of several intermediate layers for debugging.  See [these docs](https://keras.io/examples/keras_recipes/tf_serving/#custom-signature) on constructing custom Signatures.  This is fairly advanced and I'm not sure how to do this yet, or even if I would want to do this.

## Impressions

- I did not any have luck [getting dynamic batching to work](./gpu.ipynb) well.  Apparently, it can take a lot of patience and be hard to tune. [Here is a guide](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/batching/README.md#batch-scheduling-parameters-and-tuning).  More observability around this would be nice to help users tune dynamic batching.  It appears that you can setup Tensorboard to give you [some insights](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/tensorboard.md).  I tried to set this up but it was very confusing and not intuitive.  You would have to likely spend a long time with this to optimize things.
- TF Serving documentation can be confusing in places.  [This article](https://www.tensorflow.org/tfx/serving/serving_basic) on how to serve models uses a 200-line python to make a request that is pretty distracting.  Other documents are really good, like [using TF Serving with Kubernetes](https://www.tensorflow.org/tfx/serving/serving_kubernetes).
- You must specify `dtype` in your model layers as `dtype` will be used in API validation for `gRPC` requests.  Additionally, layer names are used for making requests so name those thoughtfully as well. 
- The [Keras docs](https://keras.io/examples/keras_recipes/tf_serving/) are a much more gentle introduction to TF Serving. 
- [The `SavedModel` format](https://www.tensorflow.org/guide/saved_model) is a serialization format needed for TF Serving. It's used for many things in the TF ecosystem, like TFLite, TF.js, and TF Hub.  I really like the fact that it is used across many products.
- I could not get the _exact same_ logits from my predictions with the api vs. using the model in a notebook.  Very close, but not exactly the same.  REST and grpc appear to be exactly the same though.
- It can be hard to debug the server when an error is thrown as I get a stack trace from another language.

## Notes